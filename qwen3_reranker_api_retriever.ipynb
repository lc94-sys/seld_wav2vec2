{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Retrieval with Qwen3-Reranker-8B API\n",
    "\n",
    "This notebook uses **Qwen3-Reranker-8B** deployed via inference engine API for document re-ranking.\n",
    "\n",
    "## Pipeline:\n",
    "```\n",
    "Query â†’ Hybrid Search (Qwen Embeddings + BM25) â†’ Candidates â†’ Qwen3-Reranker API â†’ Ranked Documents\n",
    "```\n",
    "\n",
    "## Components:\n",
    "- **Embeddings**: Qwen (SageMaker endpoint) - unchanged\n",
    "- **Re-Ranker**: Qwen3-Reranker-8B (your deployed API endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from typing import List, Dict, Optional\n",
    "import numpy as np\n",
    "import faiss\n",
    "import boto3\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"âœ“ Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Qwen3-Reranker API Configuration\n",
    "\n",
    "Configure your deployed Qwen3-Reranker-8B endpoint details below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURE YOUR QWEN3-RERANKER-8B API ENDPOINT HERE\n",
    "# =============================================================================\n",
    "\n",
    "# Option 1: If deployed on SageMaker (similar to your embedding endpoint)\n",
    "RERANKER_CONFIG = {\n",
    "    'type': 'sagemaker',  # or 'rest_api'\n",
    "    'endpoint_name': 'your-qwen3-reranker-endpoint',  # Replace with your endpoint name\n",
    "    'region': config['models']['embedding']['credentials']['region'],\n",
    "    'credentials': {\n",
    "        'accessKeyId': config['models']['embedding']['credentials']['accessKeyId'],\n",
    "        'secretAccessKey': config['models']['embedding']['credentials']['secretAccessKey'],\n",
    "        'sessionToken': config['models']['embedding']['credentials']['sessionToken']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Option 2: If deployed as REST API\n",
    "# RERANKER_CONFIG = {\n",
    "#     'type': 'rest_api',\n",
    "#     'url': 'https://your-reranker-api-endpoint.com/rerank',\n",
    "#     'headers': {\n",
    "#         'Content-Type': 'application/json',\n",
    "#         'Authorization': 'Bearer YOUR_API_KEY'  # if needed\n",
    "#     }\n",
    "# }\n",
    "\n",
    "print(f\"Re-ranker type: {RERANKER_CONFIG['type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Qwen3 Re-Ranker API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qwen3RerankerClient:\n",
    "    \"\"\"\n",
    "    Client for Qwen3-Reranker-8B deployed via inference engine.\n",
    "    Supports both SageMaker endpoint and REST API.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "        self.api_type = config['type']\n",
    "        \n",
    "        if self.api_type == 'sagemaker':\n",
    "            self._init_sagemaker_client()\n",
    "        elif self.api_type == 'rest_api':\n",
    "            self._init_rest_client()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown API type: {self.api_type}\")\n",
    "        \n",
    "        print(f\"âœ“ Qwen3-Reranker client initialized ({self.api_type})\")\n",
    "    \n",
    "    def _init_sagemaker_client(self):\n",
    "        \"\"\"Initialize SageMaker runtime client\"\"\"\n",
    "        self.endpoint_name = self.config['endpoint_name']\n",
    "        creds = self.config['credentials']\n",
    "        \n",
    "        self.client = boto3.client(\n",
    "            'sagemaker-runtime',\n",
    "            region_name=self.config['region'],\n",
    "            aws_access_key_id=creds['accessKeyId'],\n",
    "            aws_secret_access_key=creds['secretAccessKey'],\n",
    "            aws_session_token=creds['sessionToken']\n",
    "        )\n",
    "    \n",
    "    def _init_rest_client(self):\n",
    "        \"\"\"Initialize REST API client\"\"\"\n",
    "        self.url = self.config['url']\n",
    "        self.headers = self.config.get('headers', {'Content-Type': 'application/json'})\n",
    "    \n",
    "    def rerank(self, query: str, documents: List[str]) -> List[float]:\n",
    "        \"\"\"\n",
    "        Get relevance scores for query-document pairs.\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            documents: List of document contents (full text)\n",
    "        \n",
    "        Returns:\n",
    "            List of relevance scores (one per document)\n",
    "        \"\"\"\n",
    "        if self.api_type == 'sagemaker':\n",
    "            return self._rerank_sagemaker(query, documents)\n",
    "        else:\n",
    "            return self._rerank_rest_api(query, documents)\n",
    "    \n",
    "    def _rerank_sagemaker(self, query: str, documents: List[str]) -> List[float]:\n",
    "        \"\"\"\n",
    "        Call Qwen3-Reranker via SageMaker endpoint.\n",
    "        \n",
    "        Adjust the request format based on your deployment configuration.\n",
    "        \"\"\"\n",
    "        # Format request payload\n",
    "        # Adjust this based on your inference engine's expected format\n",
    "        payload = {\n",
    "            \"query\": query,\n",
    "            \"documents\": documents\n",
    "        }\n",
    "        \n",
    "        # Alternative format if your endpoint expects pairs:\n",
    "        # payload = {\n",
    "        #     \"pairs\": [[query, doc] for doc in documents]\n",
    "        # }\n",
    "        \n",
    "        body = json.dumps(payload)\n",
    "        \n",
    "        response = self.client.invoke_endpoint(\n",
    "            EndpointName=self.endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=body\n",
    "        )\n",
    "        \n",
    "        output_data = json.loads(response['Body'].read().decode())\n",
    "        \n",
    "        # Extract scores from response\n",
    "        # Adjust based on your endpoint's response format\n",
    "        if isinstance(output_data, list):\n",
    "            scores = output_data\n",
    "        elif 'scores' in output_data:\n",
    "            scores = output_data['scores']\n",
    "        elif 'results' in output_data:\n",
    "            scores = [r['score'] for r in output_data['results']]\n",
    "        else:\n",
    "            scores = output_data\n",
    "        \n",
    "        return [float(s) for s in scores]\n",
    "    \n",
    "    def _rerank_rest_api(self, query: str, documents: List[str]) -> List[float]:\n",
    "        \"\"\"\n",
    "        Call Qwen3-Reranker via REST API.\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"query\": query,\n",
    "            \"documents\": documents\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            self.url,\n",
    "            headers=self.headers,\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        output_data = response.json()\n",
    "        \n",
    "        # Extract scores from response\n",
    "        if isinstance(output_data, list):\n",
    "            scores = output_data\n",
    "        elif 'scores' in output_data:\n",
    "            scores = output_data['scores']\n",
    "        elif 'results' in output_data:\n",
    "            scores = [r['score'] for r in output_data['results']]\n",
    "        else:\n",
    "            scores = output_data\n",
    "        \n",
    "        return [float(s) for s in scores]\n",
    "\n",
    "print(\"âœ“ Qwen3RerankerClient class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document Retriever with Qwen3 Re-Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qwen3ReRankingRetriever:\n",
    "    \"\"\"\n",
    "    Two-stage document retriever:\n",
    "    \n",
    "    Stage 1: Hybrid search (Qwen Embeddings + BM25) for candidate retrieval\n",
    "    Stage 2: Qwen3-Reranker-8B API scores query against FULL document content\n",
    "    \n",
    "    Returns ranked document names.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict, reranker_config: dict):\n",
    "        self.config = config\n",
    "        \n",
    "        # ============================================================\n",
    "        # Initialize Qwen Embedding Client (UNCHANGED from original)\n",
    "        # ============================================================\n",
    "        self.embedding_endpoint_name = config['models']['embedding']['endpoint_name']\n",
    "        embedding_creds = config['models']['embedding']['credentials']\n",
    "        self.embedding_client = boto3.client(\n",
    "            'sagemaker-runtime',\n",
    "            region_name=embedding_creds['region'],\n",
    "            aws_access_key_id=embedding_creds['accessKeyId'],\n",
    "            aws_secret_access_key=embedding_creds['secretAccessKey'],\n",
    "            aws_session_token=embedding_creds['sessionToken']\n",
    "        )\n",
    "        print(f\"âœ“ Qwen Embedding client initialized\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # Initialize Qwen3-Reranker-8B API Client (REPLACES Llama LLM)\n",
    "        # ============================================================\n",
    "        self.reranker = Qwen3RerankerClient(reranker_config)\n",
    "        \n",
    "        # Session management\n",
    "        self.sessions = {}\n",
    "        \n",
    "        # Load indexes\n",
    "        self.load_indexes()\n",
    "    \n",
    "    def load_indexes(self):\n",
    "        \"\"\"Load FAISS and BM25 indexes\"\"\"\n",
    "        \n",
    "        # Load FAISS index\n",
    "        faiss_path = os.path.join(self.config['storage']['faiss_index'], 'faiss.index')\n",
    "        if not os.path.exists(faiss_path):\n",
    "            raise FileNotFoundError(f\"FAISS index not found at {faiss_path}\")\n",
    "        self.faiss_index = faiss.read_index(faiss_path)\n",
    "        print(f\"âœ“ FAISS index loaded\")\n",
    "        \n",
    "        # Load embeddings\n",
    "        embeddings_path = os.path.join(self.config['storage']['faiss_index'], 'embeddings.npy')\n",
    "        if os.path.exists(embeddings_path):\n",
    "            self.embeddings = np.load(embeddings_path)\n",
    "            print(f\"âœ“ Embeddings loaded: shape {self.embeddings.shape}\")\n",
    "        \n",
    "        # Load BM25 index\n",
    "        bm25_path = os.path.join(self.config['storage']['bm25_index'], 'bm25.pkl')\n",
    "        if not os.path.exists(bm25_path):\n",
    "            raise FileNotFoundError(f\"BM25 index not found at {bm25_path}\")\n",
    "        with open(bm25_path, 'rb') as f:\n",
    "            self.bm25_index = pickle.load(f)\n",
    "        print(f\"âœ“ BM25 index loaded\")\n",
    "        \n",
    "        # Load chunk metadata (contains full content)\n",
    "        metadata_path = os.path.join(self.config['storage']['faiss_index'], 'chunk_metadata.json')\n",
    "        if not os.path.exists(metadata_path):\n",
    "            raise FileNotFoundError(f\"Chunk metadata not found at {metadata_path}\")\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            self.chunks = json.load(f)\n",
    "        print(f\"âœ“ Chunk metadata loaded: {len(self.chunks)} chunks\")\n",
    "        \n",
    "        print(\"\\nâœ“ All indexes loaded successfully\")\n",
    "    \n",
    "    def get_embedding(self, text: str) -> np.ndarray:\n",
    "        \"\"\"Get embedding from Qwen SageMaker endpoint (UNCHANGED)\"\"\"\n",
    "        params = {\n",
    "            \"inputs\": [text],\n",
    "            \"encoding_format\": \"float\"\n",
    "        }\n",
    "        body = json.dumps(params)\n",
    "        \n",
    "        response = self.embedding_client.invoke_endpoint(\n",
    "            EndpointName=self.embedding_endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=body\n",
    "        )\n",
    "        output_data = json.loads(response['Body'].read().decode())\n",
    "        embedding = np.array(output_data[0], dtype='float32')\n",
    "        return embedding\n",
    "    \n",
    "    def hybrid_search(self, query: str, entitlement: str, org_id: str = None,\n",
    "                      tags: List[str] = None, top_k: int = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Stage 1: Hybrid search to retrieve candidate chunks.\n",
    "        Returns chunks with FULL CONTENT for re-ranking.\n",
    "        \"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.config['retrieval']['hybrid']['top_k']\n",
    "        \n",
    "        # Get query embedding from Qwen\n",
    "        query_embedding = self.get_embedding(query)\n",
    "        query_embedding = query_embedding.reshape(1, -1).astype('float32')\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        # Retrieve more candidates for re-ranking\n",
    "        retrieval_multiplier = 10\n",
    "        initial_top_k = min(top_k * retrieval_multiplier, len(self.chunks))\n",
    "        \n",
    "        # Vector search (FAISS)\n",
    "        vector_scores, vector_indices = self.faiss_index.search(query_embedding, initial_top_k)\n",
    "        vector_scores = vector_scores[0]\n",
    "        vector_indices = vector_indices[0]\n",
    "        \n",
    "        # Keyword search (BM25)\n",
    "        tokenized_query = query.lower().split()\n",
    "        bm25_scores = self.bm25_index.get_scores(tokenized_query)\n",
    "        \n",
    "        # Normalize scores\n",
    "        def normalize(scores):\n",
    "            min_s, max_s = scores.min(), scores.max()\n",
    "            if max_s - min_s < 1e-10:\n",
    "                return np.zeros_like(scores)\n",
    "            return (scores - min_s) / (max_s - min_s)\n",
    "        \n",
    "        vector_scores_norm = normalize(vector_scores)\n",
    "        bm25_scores_norm = normalize(bm25_scores)\n",
    "        \n",
    "        # Compute hybrid scores\n",
    "        vector_weight = self.config['retrieval']['hybrid']['vector_weight']\n",
    "        bm25_weight = self.config['retrieval']['hybrid']['bm25_weight']\n",
    "        \n",
    "        hybrid_scores = {}\n",
    "        for idx, score in zip(vector_indices, vector_scores_norm):\n",
    "            hybrid_scores[idx] = score * vector_weight\n",
    "        \n",
    "        for idx, score in enumerate(bm25_scores_norm):\n",
    "            if idx in hybrid_scores:\n",
    "                hybrid_scores[idx] += score * bm25_weight\n",
    "            else:\n",
    "                hybrid_scores[idx] = score * bm25_weight\n",
    "        \n",
    "        # Sort by hybrid score\n",
    "        sorted_indices = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Filter by entitlements and collect results WITH FULL CONTENT\n",
    "        accessible_results = []\n",
    "        \n",
    "        for idx, score in sorted_indices:\n",
    "            chunk = self.chunks[idx].copy()\n",
    "            \n",
    "            # Entitlement filter\n",
    "            chunk_entitlements = chunk['entitlement']\n",
    "            if isinstance(chunk_entitlements, str):\n",
    "                chunk_entitlements = [chunk_entitlements]\n",
    "            \n",
    "            has_access = 'universal' in chunk_entitlements or entitlement in chunk_entitlements\n",
    "            if not has_access:\n",
    "                continue\n",
    "            \n",
    "            # Org filter\n",
    "            if org_id and chunk['orgId'] != org_id:\n",
    "                continue\n",
    "            \n",
    "            # Tag filter\n",
    "            if tags and not any(t in chunk['metadata']['tags'] for t in tags):\n",
    "                continue\n",
    "            \n",
    "            chunk['hybrid_score'] = float(score)\n",
    "            accessible_results.append(chunk)\n",
    "        \n",
    "        accessible_results.sort(key=lambda x: x['hybrid_score'], reverse=True)\n",
    "        return accessible_results[:top_k]\n",
    "    \n",
    "    def rerank(self, query: str, candidates: List[Dict], top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Stage 2: Re-rank candidates using Qwen3-Reranker-8B API.\n",
    "        \n",
    "        The re-ranker receives FULL DOCUMENT CONTENT, just like the LLM did.\n",
    "        \"\"\"\n",
    "        if not candidates:\n",
    "            return []\n",
    "        \n",
    "        # Extract full document content for re-ranking\n",
    "        documents = [chunk['content'] for chunk in candidates]\n",
    "        \n",
    "        # Call Qwen3-Reranker-8B API with query and full document contents\n",
    "        rerank_scores = self.reranker.rerank(query, documents)\n",
    "        \n",
    "        # Add rerank scores to candidates\n",
    "        for i, chunk in enumerate(candidates):\n",
    "            chunk['rerank_score'] = rerank_scores[i]\n",
    "        \n",
    "        # Sort by rerank score (highest first)\n",
    "        reranked = sorted(candidates, key=lambda x: x['rerank_score'], reverse=True)\n",
    "        \n",
    "        return reranked[:top_k]\n",
    "    \n",
    "    def query(self, query: str, entitlement: str, org_id: str = None,\n",
    "              tags: List[str] = None, top_k: int = 5,\n",
    "              candidates_for_rerank: int = 20) -> Dict:\n",
    "        \"\"\"\n",
    "        Full retrieval pipeline with Qwen3-Reranker-8B.\n",
    "        \n",
    "        Args:\n",
    "            query: User's search query\n",
    "            entitlement: User's access level\n",
    "            org_id: Organization filter\n",
    "            tags: Tag filters\n",
    "            top_k: Number of final results\n",
    "            candidates_for_rerank: Number of candidates for re-ranking\n",
    "        \n",
    "        Returns:\n",
    "            Dict with ranked documents\n",
    "        \"\"\"\n",
    "        # Stage 1: Get candidates via hybrid search\n",
    "        candidates = self.hybrid_search(\n",
    "            query=query,\n",
    "            entitlement=entitlement,\n",
    "            org_id=org_id,\n",
    "            tags=tags,\n",
    "            top_k=candidates_for_rerank\n",
    "        )\n",
    "        \n",
    "        if not candidates:\n",
    "            return {\n",
    "                'query': query,\n",
    "                'documents': [],\n",
    "                'message': 'No relevant documents found.'\n",
    "            }\n",
    "        \n",
    "        # Stage 2: Re-rank using Qwen3-Reranker-8B with full document content\n",
    "        reranked = self.rerank(query, candidates, top_k=top_k)\n",
    "        \n",
    "        # Build response with unique documents\n",
    "        seen_docs = set()\n",
    "        documents = []\n",
    "        \n",
    "        for chunk in reranked:\n",
    "            doc_id = chunk['doc_id']\n",
    "            if doc_id not in seen_docs:\n",
    "                seen_docs.add(doc_id)\n",
    "                documents.append({\n",
    "                    'document_name': chunk['title'],\n",
    "                    'doc_id': doc_id,\n",
    "                    'rerank_score': chunk['rerank_score'],\n",
    "                    'hybrid_score': chunk['hybrid_score'],\n",
    "                    'content_preview': chunk['content'][:200] + '...' if len(chunk['content']) > 200 else chunk['content']\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'query': query,\n",
    "            'documents': documents,\n",
    "            'candidates_considered': len(candidates)\n",
    "        }\n",
    "    \n",
    "    # ==================== Session Management ====================\n",
    "    \n",
    "    def create_session(self, user_id: str, entitlement: str, org_id: str = None) -> str:\n",
    "        \"\"\"Create a new session\"\"\"\n",
    "        session_id = str(uuid.uuid4())\n",
    "        self.sessions[session_id] = {\n",
    "            'session_id': session_id,\n",
    "            'user_id': user_id,\n",
    "            'entitlement': entitlement,\n",
    "            'org_id': org_id,\n",
    "            'created_at': datetime.now().isoformat(),\n",
    "            'query_history': [],\n",
    "            'last_activity': datetime.now().isoformat()\n",
    "        }\n",
    "        print(f\"âœ“ Created session: {session_id}\")\n",
    "        return session_id\n",
    "    \n",
    "    def get_session(self, session_id: str) -> Optional[Dict]:\n",
    "        \"\"\"Get session data\"\"\"\n",
    "        return self.sessions.get(session_id)\n",
    "    \n",
    "    def query_with_session(self, session_id: str, query: str,\n",
    "                           tags: List[str] = None, top_k: int = 5,\n",
    "                           candidates_for_rerank: int = 20) -> Dict:\n",
    "        \"\"\"Query with session tracking\"\"\"\n",
    "        session = self.get_session(session_id)\n",
    "        if not session:\n",
    "            raise ValueError(f\"Session {session_id} not found\")\n",
    "        \n",
    "        session['last_activity'] = datetime.now().isoformat()\n",
    "        \n",
    "        result = self.query(\n",
    "            query=query,\n",
    "            entitlement=session['entitlement'],\n",
    "            org_id=session['org_id'],\n",
    "            tags=tags,\n",
    "            top_k=top_k,\n",
    "            candidates_for_rerank=candidates_for_rerank\n",
    "        )\n",
    "        \n",
    "        result['session_id'] = session_id\n",
    "        \n",
    "        # Store in history\n",
    "        session['query_history'].append({\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'query': query,\n",
    "            'documents_found': [d['document_name'] for d in result['documents']]\n",
    "        })\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_query_history(self, session_id: str, limit: int = None) -> List[Dict]:\n",
    "        \"\"\"Get query history\"\"\"\n",
    "        session = self.get_session(session_id)\n",
    "        if not session:\n",
    "            return []\n",
    "        history = session['query_history']\n",
    "        return history[-limit:] if limit else history\n",
    "    \n",
    "    def clear_session(self, session_id: str):\n",
    "        \"\"\"Clear session\"\"\"\n",
    "        if session_id in self.sessions:\n",
    "            del self.sessions[session_id]\n",
    "            print(f\"âœ“ Session {session_id} cleared\")\n",
    "    \n",
    "    def export_session(self, session_id: str, filepath: str):\n",
    "        \"\"\"Export session to JSON\"\"\"\n",
    "        session = self.get_session(session_id)\n",
    "        if session:\n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(session, f, indent=2)\n",
    "            print(f\"âœ“ Session exported to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ“ Qwen3ReRankingRetriever class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the retriever with Qwen3-Reranker-8B API\n",
    "retriever = Qwen3ReRankingRetriever(\n",
    "    config=config,\n",
    "    reranker_config=RERANKER_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test: Basic Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TEST 1: Basic Query with Qwen3-Reranker-8B\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = retriever.query(\n",
    "    query='How do I process a cancellation?',\n",
    "    entitlement='agent_support',\n",
    "    org_id='org_123',\n",
    "    tags=['cancellation'],\n",
    "    top_k=5,\n",
    "    candidates_for_rerank=20\n",
    ")\n",
    "\n",
    "print(f\"\\nQuery: {result['query']}\")\n",
    "print(f\"Candidates considered: {result.get('candidates_considered', 'N/A')}\")\n",
    "print(f\"\\nRanked Documents:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for i, doc in enumerate(result['documents'], 1):\n",
    "    print(f\"\\n{i}. {doc['document_name']}\")\n",
    "    print(f\"   Re-rank Score: {doc['rerank_score']:.4f}\")\n",
    "    print(f\"   Hybrid Score:  {doc['hybrid_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test: Compare Hybrid vs Re-Ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 2: Compare Hybrid Search vs Qwen3 Re-Ranked Results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_query = \"What documents are needed for a refund?\"\n",
    "\n",
    "# Get hybrid search results (Stage 1 only)\n",
    "hybrid_only = retriever.hybrid_search(\n",
    "    query=test_query,\n",
    "    entitlement='agent_support',\n",
    "    org_id='org_123',\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "# Get full re-ranked results\n",
    "reranked = retriever.query(\n",
    "    query=test_query,\n",
    "    entitlement='agent_support',\n",
    "    org_id='org_123',\n",
    "    top_k=5,\n",
    "    candidates_for_rerank=20\n",
    ")\n",
    "\n",
    "print(f\"\\nQuery: {test_query}\")\n",
    "\n",
    "print(f\"\\n{'BEFORE RE-RANKING (Hybrid Only)':^50}\")\n",
    "print(\"-\"*50)\n",
    "for i, chunk in enumerate(hybrid_only, 1):\n",
    "    print(f\"  {i}. {chunk['title']} (hybrid: {chunk['hybrid_score']:.4f})\")\n",
    "\n",
    "print(f\"\\n{'AFTER QWEN3 RE-RANKING':^50}\")\n",
    "print(\"-\"*50)\n",
    "for i, doc in enumerate(reranked['documents'], 1):\n",
    "    print(f\"  {i}. {doc['document_name']} (rerank: {doc['rerank_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test: Session-Based Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 3: Session-Based Queries\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create session\n",
    "session_id = retriever.create_session(\n",
    "    user_id='agent_001',\n",
    "    entitlement='agent_support',\n",
    "    org_id='org_123'\n",
    ")\n",
    "\n",
    "# Query 1\n",
    "print(\"\\n--- Query 1 ---\")\n",
    "r1 = retriever.query_with_session(session_id=session_id, query=\"How do I cancel a booking?\")\n",
    "print(f\"Query: {r1['query']}\")\n",
    "print(f\"Top Document: {r1['documents'][0]['document_name'] if r1['documents'] else 'None'}\")\n",
    "\n",
    "# Query 2\n",
    "print(\"\\n--- Query 2 ---\")\n",
    "r2 = retriever.query_with_session(session_id=session_id, query=\"What is the refund timeline?\")\n",
    "print(f\"Query: {r2['query']}\")\n",
    "print(f\"Top Document: {r2['documents'][0]['document_name'] if r2['documents'] else 'None'}\")\n",
    "\n",
    "# Show history\n",
    "print(\"\\n--- Session History ---\")\n",
    "history = retriever.get_query_history(session_id)\n",
    "for i, h in enumerate(history, 1):\n",
    "    print(f\"  {i}. {h['query']} â†’ {h['documents_found']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test: Entitlement Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 4: Entitlement-Based Access Control\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "query = \"What are the booking procedures?\"\n",
    "\n",
    "# Support agent\n",
    "support_result = retriever.query(query=query, entitlement='agent_support', org_id='org_123')\n",
    "\n",
    "# Sales agent\n",
    "sales_result = retriever.query(query=query, entitlement='agent_sales', org_id='org_123')\n",
    "\n",
    "print(f\"\\nQuery: {query}\")\n",
    "\n",
    "print(f\"\\nSupport Agent Results ({len(support_result['documents'])} docs):\")\n",
    "for doc in support_result['documents']:\n",
    "    print(f\"  ðŸ“„ {doc['document_name']} (score: {doc['rerank_score']:.4f})\")\n",
    "\n",
    "print(f\"\\nSales Agent Results ({len(sales_result['documents'])} docs):\")\n",
    "for doc in sales_result['documents']:\n",
    "    print(f\"  ðŸ“„ {doc['document_name']} (score: {doc['rerank_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROFILES = {\n",
    "    '1': {'user_id': 'agent_001', 'name': 'Alice (Support)', 'entitlement': 'agent_support', 'org_id': 'org_123'},\n",
    "    '2': {'user_id': 'agent_002', 'name': 'Bob (Sales)', 'entitlement': 'agent_sales', 'org_id': 'org_123'},\n",
    "    '3': {'user_id': 'manager_001', 'name': 'Carol (Manager)', 'entitlement': 'agent_manager', 'org_id': 'org_123'}\n",
    "}\n",
    "\n",
    "def interactive_mode():\n",
    "    \"\"\"Interactive query mode\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Interactive Document Retrieval (Qwen3-Reranker-8B)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nSelect User Profile:\")\n",
    "    for key, profile in USER_PROFILES.items():\n",
    "        print(f\"  {key}. {profile['name']}\")\n",
    "    \n",
    "    choice = input(\"\\nChoice (1-3): \").strip()\n",
    "    if choice not in USER_PROFILES:\n",
    "        print(\"Invalid choice\")\n",
    "        return\n",
    "    \n",
    "    profile = USER_PROFILES[choice]\n",
    "    session_id = retriever.create_session(\n",
    "        user_id=profile['user_id'],\n",
    "        entitlement=profile['entitlement'],\n",
    "        org_id=profile['org_id']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nLogged in as: {profile['name']}\")\n",
    "    print(\"Commands: 'quit' to exit, 'history' to see past queries\\n\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"You: \").strip()\n",
    "        \n",
    "        if query.lower() == 'quit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if query.lower() == 'history':\n",
    "            history = retriever.get_query_history(session_id)\n",
    "            for h in history:\n",
    "                print(f\"  [{h['timestamp'][:19]}] {h['query']} â†’ {h['documents_found']}\")\n",
    "            print()\n",
    "            continue\n",
    "        \n",
    "        if not query:\n",
    "            continue\n",
    "        \n",
    "        result = retriever.query_with_session(session_id=session_id, query=query)\n",
    "        \n",
    "        print(\"\\nRelevant Documents:\")\n",
    "        if result['documents']:\n",
    "            for i, doc in enumerate(result['documents'], 1):\n",
    "                print(f\"  {i}. {doc['document_name']} (score: {doc['rerank_score']:.4f})\")\n",
    "        else:\n",
    "            print(\"  No relevant documents found.\")\n",
    "        print()\n",
    "\n",
    "# Uncomment to run:\n",
    "# interactive_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Pipeline:\n",
    "```\n",
    "Query\n",
    "  â†“\n",
    "Hybrid Search (Qwen Embeddings + BM25)\n",
    "  â†“\n",
    "20 Candidate Chunks (with full content)\n",
    "  â†“\n",
    "Qwen3-Reranker-8B API (scores query vs full content)\n",
    "  â†“\n",
    "Top 5 Ranked Documents\n",
    "```\n",
    "\n",
    "### API Request Format:\n",
    "```python\n",
    "# Request to Qwen3-Reranker-8B API:\n",
    "{\n",
    "    \"query\": \"How do I process a cancellation?\",\n",
    "    \"documents\": [\n",
    "        \"Full content of document 1...\",\n",
    "        \"Full content of document 2...\",\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Response:\n",
    "{\n",
    "    \"scores\": [0.92, 0.85, 0.71, ...]\n",
    "}\n",
    "```\n",
    "\n",
    "### Note:\n",
    "Adjust the request/response format in `Qwen3RerankerClient` based on your inference engine's API specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NOTEBOOK COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nQwen3-Reranker-8B API configured.\")\n",
    "print(\"The re-ranker receives FULL document content (like the LLM did).\")\n",
    "print(\"It outputs relevance scores to rank documents.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
